{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting Started with TensorFlow low-precision int8 inference\n",
    "\n",
    "This code sample will serve as a sample use case to perform low precision int8 inference on a synthetic data implementing a ResNet50 pre-trained model. The pre-trained model published as part of Intel Model Zoo will be used in this sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/intel/inteloneapi/tensorflow/latest/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-11 23:51:22--  https://storage.googleapis.com/intel-optimized-tensorflow/models/resnet50_int8_pretrained_model.pb\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.176, 216.58.194.144, 172.217.1.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31868512 (30M) [application/octet-stream]\n",
      "Saving to: ‘resnet50_int8_pretrained_model.pb’\n",
      "\n",
      "resnet50_int8_pretr 100%[===================>]  30.39M  22.1MB/s    in 1.4s    \n",
      "\n",
      "2020-07-11 23:51:24 (22.1 MB/s) - ‘resnet50_int8_pretrained_model.pb’ saved [31868512/31868512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download Intel's pretrained resnet50 model\n",
    "try:\n",
    "    !wget https://storage.googleapis.com/intel-optimized-tensorflow/models/resnet50_int8_pretrained_model.pb\n",
    "except:\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve('https://storage.googleapis.com/intel-optimized-tensorflow/models/resnet50_int8_pretrained_model.pb', 'resnet50_int8_pretrained_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset of size 244x244.\n",
    "It is important to set optimial batch_size, MKL run-time settings, TensorFlow's inter-intra number of threads to enable compute and data layer optimizations. We have identified  optimial settings for popular topologies including ResNet50 to maximize CPU utlization. For more details on Run-time settings refer to blogs [maximize CPU performance](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference), [Intel Model Zoo tutorials](https://github.com/IntelAI/models/tree/master/docs). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    physical_cores= !lscpu -b -p=Core,Socket | grep -v '^#' | sort -u | wc -l\n",
    "except:\n",
    "    physical_cores = [str(os.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"resnet50_int8_pretrained_model.pb\"\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "batch_size = 64\n",
    "input_layer = \"input\" # input tensor name from the stored graph\n",
    "output_layer = \"predict\"# input tensor name to be computed\n",
    "warmup_steps = 10\n",
    "steps = 50\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]= physical_cores[0]\n",
    "num_inter_threads = 2\n",
    "num_intra_threads = int(physical_cores[0])\n",
    "data_config = tf.ConfigProto()\n",
    "data_config.intra_op_parallelism_threads = 16 \n",
    "data_config.inter_op_parallelism_threads = 14 \n",
    "data_config.use_per_session_threads = 1\n",
    "\n",
    "infer_config = tf.ConfigProto()\n",
    "infer_config.intra_op_parallelism_threads = num_intra_threads\n",
    "infer_config.inter_op_parallelism_threads = num_inter_threads\n",
    "infer_config.use_per_session_threads = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data graph, and infer graph from pre-trained int8 resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = tf.Graph()\n",
    "with data_graph.as_default():\n",
    "    input_shape = [batch_size, input_height, input_width, 3]\n",
    "    images = tf.random.uniform(input_shape, 0.0, 255.0, dtype=tf.float32, name='synthetic_images')\n",
    "\n",
    "infer_graph = tf.Graph()\n",
    "with infer_graph.as_default():\n",
    "    graph_def = tf.GraphDef()\n",
    "    with open(model_file, \"rb\") as f:\n",
    "      graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data and infer sessions for optimized data access and graph computation configured with best thread settings for Resnet50 and run warm-up steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Running warmup steps...]\n",
      "steps = 10, 124.74021587801981 images/sec\n"
     ]
    }
   ],
   "source": [
    "input_tensor = infer_graph.get_tensor_by_name(input_layer + \":0\")\n",
    "output_tensor = infer_graph.get_tensor_by_name(output_layer + \":0\")\n",
    "tf.global_variables_initializer()\n",
    "\n",
    "data_sess = tf.Session(graph=data_graph, config=data_config)\n",
    "infer_sess = tf.Session(graph=infer_graph, config=infer_config)\n",
    "\n",
    "print(\"[Running warmup steps...]\")\n",
    "step_total_time = 0\n",
    "step_total_images = 0\n",
    "\n",
    "for t in range(warmup_steps):\n",
    "    data_start_time = time.time()\n",
    "    image_data = data_sess.run(images)\n",
    "    data_load_time = time.time() - data_start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    step_total_time += elapsed_time\n",
    "    step_total_images += batch_size\n",
    "\n",
    "    if ((t + 1) % 10 == 0):\n",
    "      print(\"steps = {0}, {1} images/sec\"\n",
    "            \"\".format(t + 1, step_total_images / step_total_time))\n",
    "      step_total_time = 0\n",
    "      step_total_images = 0\n",
    "\n",
    "total_time = 0\n",
    "total_images = 0\n",
    "\n",
    "step_total_time = 0\n",
    "step_total_images = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training steps with batch size 64 to measure average throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Running benchmark steps...]\n",
      "steps = 10, 188.9646254119768 images/sec\n",
      "steps = 20, 194.3488418042139 images/sec\n",
      "steps = 30, 157.4982258854042 images/sec\n",
      "steps = 40, 141.00398173325632 images/sec\n",
      "steps = 50, 155.36436378680366 images/sec\n",
      "Average throughput for batch size 64: 164.9340815321478 images/sec\n"
     ]
    }
   ],
   "source": [
    "print(\"[Running benchmark steps...]\")\n",
    "for t in range(steps):\n",
    "    try:\n",
    "      data_start_time = time.time()\n",
    "      image_data = data_sess.run(images)\n",
    "      data_load_time = time.time() - data_start_time\n",
    "\n",
    "      start_time = time.time()\n",
    "      infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "      elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "      total_time += elapsed_time\n",
    "      total_images += batch_size\n",
    "\n",
    "      step_total_time += elapsed_time\n",
    "      step_total_images += batch_size\n",
    "\n",
    "      if ((t + 1) % 10 == 0):\n",
    "        print(\"steps = {0}, {1} images/sec\"\n",
    "              \"\".format(t + 1, step_total_images / step_total_time))\n",
    "        step_total_time = 0\n",
    "        step_total_images = 0\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"Running out of images from dataset.\")\n",
    "      break\n",
    "\n",
    "print(\"Average throughput for batch size {0}: {1} images/sec\".format(batch_size, total_images / total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-11 23:51:50--  https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/inceptionv4_int8_pretrained_model.pb\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.176, 216.58.194.144, 172.217.1.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47651527 (45M) [application/octet-stream]\n",
      "Saving to: ‘inceptionv4_int8_pretrained_model.pb’\n",
      "\n",
      "inceptionv4_int8_pr 100%[===================>]  45.44M  22.6MB/s    in 2.0s    \n",
      "\n",
      "2020-07-11 23:51:53 (22.6 MB/s) - ‘inceptionv4_int8_pretrained_model.pb’ saved [47651527/47651527]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download Intel's pretrained resnet50 model\n",
    "try:\n",
    "    !wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/inceptionv4_int8_pretrained_model.pb\n",
    "except:\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve('https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/inceptionv4_int8_pretrained_model.pb', 'inceptionv4_int8_pretrained_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset of size 244x244.\n",
    "It is important to set optimial batch_size, MKL run-time settings, TensorFlow's inter-intra number of threads to enable compute and data layer optimizations. We have identified  optimial settings for popular topologies including ResNet50 to maximize CPU utlization. For more details on Run-time settings refer to blogs [maximize CPU performance](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference), [Intel Model Zoo tutorials](https://github.com/IntelAI/models/tree/master/docs). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    physical_cores= !lscpu -b -p=Core,Socket | grep -v '^#' | sort -u | wc -l\n",
    "except:\n",
    "    physical_cores = [str(os.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"resnet50_int8_pretrained_model.pb\"\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "batch_size = 64\n",
    "input_layer = \"input\" # input tensor name from the stored graph\n",
    "output_layer = \"predict\"# input tensor name to be computed\n",
    "warmup_steps = 10\n",
    "steps = 50\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]= physical_cores[0]\n",
    "num_inter_threads = 2\n",
    "num_intra_threads = int(physical_cores[0])\n",
    "data_config = tf.ConfigProto()\n",
    "data_config.intra_op_parallelism_threads = 16 \n",
    "data_config.inter_op_parallelism_threads = 14 \n",
    "data_config.use_per_session_threads = 1\n",
    "\n",
    "infer_config = tf.ConfigProto()\n",
    "infer_config.intra_op_parallelism_threads = num_intra_threads\n",
    "infer_config.inter_op_parallelism_threads = num_inter_threads\n",
    "infer_config.use_per_session_threads = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data graph, and infer graph from pre-trained int8 inceptionV4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = tf.Graph()\n",
    "with data_graph.as_default():\n",
    "    input_shape = [batch_size, input_height, input_width, 3]\n",
    "    images = tf.random.uniform(input_shape, 0.0, 255.0, dtype=tf.float32, name='synthetic_images')\n",
    "\n",
    "infer_graph = tf.Graph()\n",
    "with infer_graph.as_default():\n",
    "    graph_def = tf.GraphDef()\n",
    "    with open(model_file, \"rb\") as f:\n",
    "      graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data and infer sessions for optimized data access and graph computation configured with best thread settings for InceptionV4 and run warm-up steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Running warmup steps...]\n",
      "steps = 10, 118.6054757386634 images/sec\n"
     ]
    }
   ],
   "source": [
    "input_tensor = infer_graph.get_tensor_by_name(input_layer + \":0\")\n",
    "output_tensor = infer_graph.get_tensor_by_name(output_layer + \":0\")\n",
    "tf.global_variables_initializer()\n",
    "\n",
    "data_sess = tf.Session(graph=data_graph, config=data_config)\n",
    "infer_sess = tf.Session(graph=infer_graph, config=infer_config)\n",
    "\n",
    "print(\"[Running warmup steps...]\")\n",
    "step_total_time = 0\n",
    "step_total_images = 0\n",
    "\n",
    "for t in range(warmup_steps):\n",
    "    data_start_time = time.time()\n",
    "    image_data = data_sess.run(images)\n",
    "    data_load_time = time.time() - data_start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    step_total_time += elapsed_time\n",
    "    step_total_images += batch_size\n",
    "\n",
    "    if ((t + 1) % 10 == 0):\n",
    "      print(\"steps = {0}, {1} images/sec\"\n",
    "            \"\".format(t + 1, step_total_images / step_total_time))\n",
    "      step_total_time = 0\n",
    "      step_total_images = 0\n",
    "\n",
    "total_time = 0\n",
    "total_images = 0\n",
    "\n",
    "step_total_time = 0\n",
    "step_total_images = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training steps with batch size 64 to measure average throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Running benchmark steps...]\n",
      "steps = 10, 144.4954665690859 images/sec\n",
      "steps = 20, 154.08671709144747 images/sec\n",
      "steps = 30, 167.90160164101513 images/sec\n",
      "steps = 40, 142.96600361713735 images/sec\n",
      "steps = 50, 140.33903607554305 images/sec\n",
      "Average throughput for batch size 64: 149.31334611354987 images/sec\n"
     ]
    }
   ],
   "source": [
    "print(\"[Running benchmark steps...]\")\n",
    "for t in range(steps):\n",
    "    try:\n",
    "      data_start_time = time.time()\n",
    "      image_data = data_sess.run(images)\n",
    "      data_load_time = time.time() - data_start_time\n",
    "\n",
    "      start_time = time.time()\n",
    "      infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "      elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "      total_time += elapsed_time\n",
    "      total_images += batch_size\n",
    "\n",
    "      step_total_time += elapsed_time\n",
    "      step_total_images += batch_size\n",
    "\n",
    "      if ((t + 1) % 10 == 0):\n",
    "        print(\"steps = {0}, {1} images/sec\"\n",
    "              \"\".format(t + 1, step_total_images / step_total_time))\n",
    "        step_total_time = 0\n",
    "        step_total_images = 0\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"Running out of images from dataset.\")\n",
    "      break\n",
    "\n",
    "print(\"Average throughput for batch size {0}: {1} images/sec\".format(batch_size, total_images / total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnt101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-11 23:52:21--  https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/resnet101_fp32_pretrained_model.pb\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.176, 216.58.194.144, 172.217.1.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 178090453 (170M) [application/octet-stream]\n",
      "Saving to: ‘resnet101_fp32_pretrained_model.pb’\n",
      "\n",
      "resnet101_fp32_pret 100%[===================>] 169.84M  23.0MB/s    in 7.4s    \n",
      "\n",
      "2020-07-11 23:52:29 (23.0 MB/s) - ‘resnet101_fp32_pretrained_model.pb’ saved [178090453/178090453]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download Intel's pretrained resnet50 model\n",
    "try:\n",
    "    !wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/resnet101_fp32_pretrained_model.pb\n",
    "except:\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve('https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/resnet101_fp32_pretrained_model.pb', 'resnet101_fp32_pretrained_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset of size 244x244.\n",
    "It is important to set optimial batch_size, MKL run-time settings, TensorFlow's inter-intra number of threads to enable compute and data layer optimizations. We have identified  optimial settings for popular topologies including ResNet50 to maximize CPU utlization. For more details on Run-time settings refer to blogs [maximize CPU performance](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference), [Intel Model Zoo tutorials](https://github.com/IntelAI/models/tree/master/docs). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    physical_cores= !lscpu -b -p=Core,Socket | grep -v '^#' | sort -u | wc -l\n",
    "except:\n",
    "    physical_cores = [str(os.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"resnet50_int8_pretrained_model.pb\"\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "batch_size = 64\n",
    "input_layer = \"input\" # input tensor name from the stored graph\n",
    "output_layer = \"predict\"# input tensor name to be computed\n",
    "warmup_steps = 10\n",
    "steps = 50\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]= physical_cores[0]\n",
    "num_inter_threads = 2\n",
    "num_intra_threads = int(physical_cores[0])\n",
    "data_config = tf.ConfigProto()\n",
    "data_config.intra_op_parallelism_threads = 16 \n",
    "data_config.inter_op_parallelism_threads = 14 \n",
    "data_config.use_per_session_threads = 1\n",
    "\n",
    "infer_config = tf.ConfigProto()\n",
    "infer_config.intra_op_parallelism_threads = num_intra_threads\n",
    "infer_config.inter_op_parallelism_threads = num_inter_threads\n",
    "infer_config.use_per_session_threads = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data graph, and infer graph from pre-trained int8 resnet101 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = tf.Graph()\n",
    "with data_graph.as_default():\n",
    "    input_shape = [batch_size, input_height, input_width, 3]\n",
    "    images = tf.random.uniform(input_shape, 0.0, 255.0, dtype=tf.float32, name='synthetic_images')\n",
    "\n",
    "infer_graph = tf.Graph()\n",
    "with infer_graph.as_default():\n",
    "    graph_def = tf.GraphDef()\n",
    "    with open(model_file, \"rb\") as f:\n",
    "      graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data and infer sessions for optimized data access and graph computation configured with best thread settings for Resnet101 and run warm-up steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Running warmup steps...]\n",
      "steps = 10, 132.0286208505563 images/sec\n"
     ]
    }
   ],
   "source": [
    "input_tensor = infer_graph.get_tensor_by_name(input_layer + \":0\")\n",
    "output_tensor = infer_graph.get_tensor_by_name(output_layer + \":0\")\n",
    "tf.global_variables_initializer()\n",
    "\n",
    "data_sess = tf.Session(graph=data_graph, config=data_config)\n",
    "infer_sess = tf.Session(graph=infer_graph, config=infer_config)\n",
    "\n",
    "print(\"[Running warmup steps...]\")\n",
    "step_total_time = 0\n",
    "step_total_images = 0\n",
    "\n",
    "for t in range(warmup_steps):\n",
    "    data_start_time = time.time()\n",
    "    image_data = data_sess.run(images)\n",
    "    data_load_time = time.time() - data_start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    step_total_time += elapsed_time\n",
    "    step_total_images += batch_size\n",
    "\n",
    "    if ((t + 1) % 10 == 0):\n",
    "      print(\"steps = {0}, {1} images/sec\"\n",
    "            \"\".format(t + 1, step_total_images / step_total_time))\n",
    "      step_total_time = 0\n",
    "      step_total_images = 0\n",
    "\n",
    "total_time = 0\n",
    "total_images = 0\n",
    "\n",
    "step_total_time = 0\n",
    "step_total_images = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training steps with batch size 64 to measure average throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Running benchmark steps...]\n",
      "steps = 10, 143.25923368995046 images/sec\n"
     ]
    }
   ],
   "source": [
    "print(\"[Running benchmark steps...]\")\n",
    "for t in range(steps):\n",
    "    try:\n",
    "      data_start_time = time.time()\n",
    "      image_data = data_sess.run(images)\n",
    "      data_load_time = time.time() - data_start_time\n",
    "\n",
    "      start_time = time.time()\n",
    "      infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "      elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "      total_time += elapsed_time\n",
    "      total_images += batch_size\n",
    "\n",
    "      step_total_time += elapsed_time\n",
    "      step_total_images += batch_size\n",
    "\n",
    "      if ((t + 1) % 10 == 0):\n",
    "        print(\"steps = {0}, {1} images/sec\"\n",
    "              \"\".format(t + 1, step_total_images / step_total_time))\n",
    "        step_total_time = 0\n",
    "        step_total_images = 0\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"Running out of images from dataset.\")\n",
    "      break\n",
    "\n",
    "print(\"Average throughput for batch size {0}: {1} images/sec\".format(batch_size, total_images / total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code Credits: Intel Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
